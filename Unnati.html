<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dark Data 2022</title>
    <link rel="stylesheet" href="css/styles.css">
    <!-- close button-->
    <link rel="stylesheet" href="https://fonts.sandbox.google.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
    <link href='https://fonts.googleapis.com/css?family=IBM Plex Sans Condensed' rel='stylesheet'>

</head>

<body>
  <div class = "container">
    <input type="checkbox" id="mycheckbox">
    <label for="mycheckbox" class="about-label" id="about-label">about</label>
    <form class="form">

      <div id="sideNote">
        <p>
          This digital edition was compiled from scholarship,research, and creative practice in sping 2022 to fulfill the requirements for PSAM 5752 Dark Data, a course at Parsons School of Design
        </p>

        <p>
          <b>Editors</b> <br> Malik Pierre-Davis <br> Momo Gao
        </p>

        <p>
          <b>Art Directors</b> <br> Goncalo Monte <br> Leanne Huang
        </p>

        <p>
          <b>Technical Directors</b> <br> Ziyan Cai <br> Lawrence Duan
        </p>

        <p>
          <b>Faculty</b> <br> David Carroll
        </p>

        <p>
          <b>Contributors</b>
        </p>

      </div>
    </form>
    <div class="nav">nav
    </div>
    <div class="header">
      <div id="top-bar">
        <div id="top-left"><h4 style="color: #0809a3">MFADT</h4></div>
        <div id="top-mid"><h4 style="color: #0809a3">Dark Data</h4></div>
        <div id="top-right"><select onChange="window.location.href=this.value" id="years">
          <option>Dark Data 2022▼</option>
          <option value="https://mfadt.parsons.edu/darkdata/2021/index.html">Dark Data 2021</option>
          <option value="https://mfadt.parsons.edu/darkdata/2019/index.html">Dark Data 2019</option>
        </select></div>
    </div>
  </div>
    <div class="content">
      <div class="filler">
      </div>
      <div class="frame_article">
        <div class="modal-header">
          <div class="title"><h2>My Simulated Mental Illness
</h2></div>

          <p class='separator'></p>
          <button class="close-button">
            <span class="material-symbols-outlined" id="back-button" style="font-size:36px;">
            indeterminate_check_box
            </span></button>
        </div>
        <div class="article">
        <br>
          <h1>My Simulated Mental Illness</h1>
          <h2>Unnati Shukla</h2>
          <br>
          <p>I am depressed, or at least my therapist and my for-you-page on TikTok tell me I am (so that must mean it’s true??). I recently started taking Wellbutrin, an NDRI meant to treat depression and anxiety. Soon after, I started getting content in the form of targeted ads, suggested content on Twitter, and my TikTok for-you-page, offering up preconceived notions of what it’s like taking the drug and what it means to be a “Wellbutrin girly” in her “Mitski era.” When did I become a simulation of myself?</p>

          <br>
          <p>Nowadays, people cultivate their sense of self through a desire to fit into a subculture, rather than intuition. We try to individualize ourselves with labels and archetypes instead of pure pursuit of being ourselves. This makes us more vulnerable to profiteering from surveillance companies. We have collectively begun to heavily identify with our own <u>User Profile Information</u> (UPI) that companies have aggregated on us. As subjects that are constantly being surveilled, we have become consumed with our own performance and labeling. We surveille ourselves, therefore the observer effect has become internalized. We live in our own simulacra. How has the internalized “observer effect” resulted in a commodification of mental illness, where people create identities and communities mainly driven by their own neuroses?
</p>
          <br>
          <p>In Surveillance Capitalism, Shoshana Zuboff introduces a few terms that can help contextualize the simulacra that has been created with mental illness and internet culture.The emergence of surveillance capitalism began with the <u>behavioral value reinvestment cycle</u>, a model in which all behavioral data is reinvested in the improvement of the product or service. Products at big tech companies, or the omnipotent “algorithm,” are about predicting us, without actually caring what we do or what is done to us (Zuboff, 2014). It benefits social media companies to know when I am getting tired, as that could perhaps inform the next iteration to think about how to keep users engaged and ignore my own physiological internal signals of needing rest.
</p>
        <br>
        <p>
          Tools like Google Ads learned about the “untapped market” of <u>behavioral surplus</u>, or data that goes beyond online product and service use. Surveillance capitalism’s profits are derived primarily from these behavioral futures markets. If companies can use your data to predict what your next move, want, or desire is, it can serve you ads accordingly; therefore subtly but constantly shaping your perceptions and behaviors, even ones you may hold about yourself. Buying this thing will virtue-signal to others that I’m a part of this community, that I embody this trait. This ethos-based tactic has been used for decades in marketing, but the difference now lies in the subtleties of identity-generation that is constantly fed to us through both organic and marketed content. Some data would continue to be applied to service improvement, but the growing stores of collateral signals would be repurposed to improve the profitability of ads for both Google and its advertisers (Zuboff, 2014).
        </p>
        <br>
        <p>This market opportunity soon created the genesis of <u>User Profile Information</u> (UPI), data which “may be inferred,” “presumed,” and “deduced.” New methods and computational tools can create UPI from integrating and analyzing a user’s search patterns, document inquiries, and myriad of other signals of online behaviors, even when users do not directly provide that personal information. In my UPI, it is presumed that I’m on antidepressants – perhaps Google scoured my Calendar to see I had an upcoming psych appointment, or they could infer so much based on the fact that I was listening to “Moon Song'' by Phoebe Bridgers at 8 A.M.</p>
        <br>
        <p>UPI technology, which informed surveillance capitalism, revealed new capabilities to infer and deduce the thoughts, feelings, intentions, and interests of individuals and groups with an automated architecture that operates as a one-way mirror irrespective of a person’s awareness, knowledge, and consent, thus enabling privileged secret access to behavioral data.
This mechanic produces an effect in which we are sorted, categorized, and almost pigeon-holed into groups. The subtleties by which this is enacted make it insidious.How do we become conscious of these mechanisms that are shaping our behaviors and understand who we truly are vs. what elements of ourselves are fed to us?
</p>
        <br>
        <p>In <i>Simulacra and Simulation</i> (1983) Baudrillard claims that our society, has “replaced all reality and meaning with symbols and signs, and that human experience is a simulation of reality.” He describes three types of simulacra:</p>
        <br>
        <p>Baudrillard begins with the first order, where <b>representation is clearly an artificial place-marker</b> for the real item. It is optimistic and utopian, and believed equating representation and reality was impossible. In surveillance capitalism and internet culture today, this could be marked by the initial dissemination of meme content to relate to others who have shared experiences. Online, we may reduce ourselves to stereotypes, but in a way, that is strategic and conscious – as an attempt to connect with others. We find safety in categorization and labels, but what are the implications of our illnesses becoming part of our meme-able identities? </p>
        <br>
        <p>Then follows the second order, where distinctions between representation and reality break down due to the <b>proliferation of mass-reproducible copies of items, turning them into commodities</b>. The commodity’s ability to imitate reality threatens to replace the authority of the original version because the copy is just as “real” as its prototype. This phenomenon is marked by community formation within these communities. </p>
        <br>
        <p>How does this impact us as users of the internet? It has become easy to compactify illness into a consumable package, to whittle at the edges of pathology. Depression is now a brooding mystique; it’s easier to broadcast and sell pain than to sit and live with it. Even when I am seemingly at my lowest, I am still filtering my experiences through the eyes of a consumer, or those who surveil me. The desire to curate our own experiences, to romanticize the unseen, to live for our biographies has become an autonomic facet of modern-day human suffering. Social media is crafting the overpowering desire to be different while also defining exactly what qualifies. In turn, everyone, in their attempts to be individual, ends up becoming the same. </p>
        <br>
        <p>The danger of this with mental illness is twofold. First, it results in the mass misdiagnoses of neurodivergent folks – reducing the stigma has progressed into an entire colloquialization of life-threatening diseases. Second, this commodification turns into a romanticization of serious clinical disorders:a mass dismissal of illness, as it moves from a clinical issue to a quirky personality trait. </p>
        <br>
        <p>Last is the third order, where <b>the simulacrum precedes the original</b> and the distinction between reality and representation vanishes. There is only the simulacrum:originality becomes a totally meaningless concept as massively produced copies threaten the source, the real object, the original reference. With respect to my UPI, it seems my identity of being depressed precedes the diagnosis.</p>
        <br>
        <p>	Behavioral surplus shows a direct path to how we got to the third order. Personality analysis for commercial advantage is built on behavioral surplus—the so-called meta-data or mid-level metrics—honed and tested by researchers and destined to foil anyone who thinks that she is in control of the “amount” of personal information that she reveals in social media. The new toolmakers of surveillance capitalism do not intend to rob you of your inner life, only to exploit it. Zuboff remarks, “All they ask is to know more about you than you know about yourself” (Zuboff, 2014).</p>
        <br>
        <p>We live in a new frontier of behavioral surplus where the dark data continent of your inner life—your intentions and motives, meanings and needs, preferences and desires, moods and emotions, personality and disposition, truth telling or deceit—is summoned into the light for others’ profit.  “The point is not to cure ailments, but to render all of it as immeasurably tiny bits of behavior available for calculation so that each can take its place on the assembly line”(Zuboff, 2014).. Human experience, from moments of euphoria to clinical illness, is subjugated to surveillance capitalism’s market mechanisms and reborn as “behavior.” These behaviors are rendered into data, ready to take their place in a numberless queue that feeds the machines for fabrication into predictions and eventual exchange in the new behavioral futures markets.</p>
        <br>
        <p>One phenomenon of the third order is dissimulation, which in the context of social media, internet culture, and the information ecosystem, we have already seen through two examples:</p>
        <br>
        <p>
In <i>Simulacra in the Age of Social Media</i>, James Morris discusses how the sharing of “fake news” via social media is merely the latest incarnation of this phenomenon. Simulated news can potentially be even more successful than “real” news in this context because the factuality of a story is secondary to users’ engagement with it. This has serious consequences for civic life. The current failure of news organizations to cope with the increased drive towards simulation in media poses an important question regarding political power and our ability to do effective journalism about it (Morris, 2021). Within the wellness community, I fell victim to the fake news thinly-veiled as healthy eating habits (truly just disordered eating tips), that were very popular in the early 2010s Tumblr “thinspo”/”fitspo” community.</p>
        <br>
        <p>The second dissimulation is masking a strengthening of morality: of a moral panic as one approaches the primitive <i>(mise en) scene</i> of capital” (Baudrillard, 1983). This is the other side of mental health commodification: the moral panic surveillance companies have induced through dissumalting/deflection tactics. How have we come to simultaneously fear, yet glamorize and identify with, mental illness?</p>
        <br>
        <p>Earlier this year, Meta ran a mental-illness smear campaign against TikTok as a way to deflect from its own privacy and antitrust concerns. On March 12, a letter to the editor that Targeted Victory officials helped orchestrate ran in the Denver Post. The letter, from a “concerned” “new parent,” claimed that TikTok was harmful to children’s mental health, raised concerns over its data privacy practices, and said that “many people even suspect China is deliberately collecting behavioral data on our kids” as if Meta isn’t doing exactly the same thing (Lorenz, 2022). The letter also issued support for Colorado Attorney General Phil Weiser’s choice to join a coalition of state attorneys general investigating TikTok’s impact on American youths, putting political pressure on the company.”</p>
        <br>
        <p> Is every competing platform’s action objectively bad, or is it a Facebook mise-en-scene to discredit alternative threats to power? This smear-campaign specifically signals how we have entered a logic of simulation, which has nothing to do with order and reason. This has become increasingly more noticeable within a tech industry where companies vie for cultural relevance. The same commodity we have weaponized as users in an attempt to find community has also been used as a distress signal to others not on the platform of how bad things can get.</p>
        <br>
        <p>Just as I reassure myself that I am drawn to this media because of some predetermined, inherent sense of self, I wonder how it is creating me, too. Is the process of developing my UPI  an infinite feedback loop? Or is it a set list of instructions, directing me who and how to be?

</p>
        <br>
        <p>Who would I be if I stopped consuming content? What would there be left to feel, to exist as? I consume so much, now, that perhaps I don’t know what it means to exist as something unsellable. </p>
        <br>
        <hr>
        <p>Unnati Shukla is a first-year MFADT student. She is fascinated by the intersection of global mental health, culture, and technology. – <a href="http://www.twitter.com/illum_unnati">Twitter</a></p>
        <br>
        <p>Sources:</p>
        <ul>
          <li>Baudrillard, J. (1994). Simulacra and Simulation (S. Glaser, Trans.). University of Michigan Press.</li>
          <li>Best, P., Manktelow, R., & Taylor, B. (2014). Online communication, social media and adolescent wellbeing: A systematic narrative review. Children and Youth Services Review, 41, 27-36.</li>
          <li>Zuboff, S., & Schwandt, K. (2019). The age of surveillance capitalism: the fight for a human future at the new frontier of power. Profile Books.</li>
          <li>Lorenz, T., & Harwell, D. (2022). Facebook paid GOP firm to malign TikTok. <i>The Washington Post</i>. Retrieved from <a href="https://www.washingtonpost.com">https://www.washingtonpost.com</a>.</li>
          <li>Tolentino, J. (2019). <i>Trick Mirror: Reflections on self-delusion</i>.</li>
          <li>Morris, J. (2021). Simulacra in the Age of Social Media: Baudrillard as the Prophet of Fake News. Journal of Communication Inquiry, 45(4), 319–336. <a href="https://doi.org/10.1177/0196859920977154">https://doi.org/10.1177/0196859920977154</a></li>
        </ul>
        </div>
      </div>
    </div>
    <script type="text/javascript">
        document.getElementById("back-button").onclick = function () {
            location.href = "index.html";
        };
    </script>
</body>
</html>
